{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9522503e",
   "metadata": {},
   "source": [
    "# DLT Framework Quick Start Guide\n",
    "\n",
    "Welcome to the Deep Learning Toolkit (DLT) framework! This notebook will walk you through the essential features and show you how to get started with both sklearn and PyTorch models.\n",
    "\n",
    "## What is DLT?\n",
    "\n",
    "DLT is a universal machine learning framework that provides:\n",
    "- **Unified API** for sklearn, PyTorch, TensorFlow, and JAX\n",
    "- **Smart Configuration** with automatic validation\n",
    "- **Advanced Features** like hyperparameter optimization, mixed precision training\n",
    "- **Production Ready** with comprehensive logging and monitoring\n",
    "\n",
    "Let's dive in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e3ea237",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 12:06:23.140557: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ DLT Framework imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rlfowler/Documents/myprojects/DLT/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Install DLT if needed (uncomment if running locally)\n",
    "# !pip install -e .\n",
    "\n",
    "# Import essential modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DLT imports\n",
    "from dlt.core.config import DLTConfig\n",
    "from dlt.core.model import DLTModel\n",
    "from dlt.core.pipeline import train, evaluate, predict, tune\n",
    "\n",
    "print(\"✅ DLT Framework imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43ed1db",
   "metadata": {},
   "source": [
    "## 🚀 Example 1: Sklearn Classification\n",
    "\n",
    "Let's start with a simple classification task using scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71859128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (800, 20)\n",
      "Test data shape: (200, 20)\n",
      "Number of classes: 3\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, \n",
    "    n_features=20, \n",
    "    n_classes=3, \n",
    "    n_informative=15,\n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n",
    "print(f\"Number of classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f69e7654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📋 Configuration created:\n",
      "Model: sklearn.ensemble.RandomForestClassifier\n",
      "Experiment: sklearn_quickstart\n"
     ]
    }
   ],
   "source": [
    "# Create a DLT configuration for Random Forest\n",
    "config = DLTConfig(\n",
    "    model_type='sklearn.ensemble.RandomForestClassifier',\n",
    "    model_params={\n",
    "        'n_estimators': 100,\n",
    "        'max_depth': 10,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'sklearn_quickstart',\n",
    "        'tags': ['classification', 'random_forest']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"📋 Configuration created:\")\n",
    "print(f\"Model: {config.model_type}\")\n",
    "print(f\"Experiment: {config.experiment['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6af9ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with sklearn.ensemble.RandomForestClassifier\n",
      "Framework: sklearn\n",
      "Device: cuda:0\n",
      "Training sklearn.ensemble.RandomForestClassifier...\n",
      "Training completed in 0.23s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.8100\n",
      "Training completed in 0.23 seconds\n",
      "\n",
      "🎯 Training Results:\n",
      "Training completed in 0.23 seconds\n",
      "Test accuracy: 0.81\n",
      "Training completed in 0.23s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.8100\n",
      "Training completed in 0.23 seconds\n",
      "\n",
      "🎯 Training Results:\n",
      "Training completed in 0.23 seconds\n",
      "Test accuracy: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Train the model using DLT's high-level API\n",
    "results = train(\n",
    "    config=config,\n",
    "    train_data=(X_train, y_train),\n",
    "    test_data=(X_test, y_test),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n🎯 Training Results:\")\n",
    "print(f\"Training completed in {results['training_time']:.2f} seconds\")\n",
    "print(f\"Test accuracy: {results.get('test_results', {}).get('accuracy', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6a191e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔮 Predictions for first 5 test samples:\n",
      "Sample 1: Predicted=0, Actual=0, Confidence=0.792\n",
      "Sample 2: Predicted=2, Actual=2, Confidence=0.663\n",
      "Sample 3: Predicted=1, Actual=1, Confidence=0.652\n",
      "Sample 4: Predicted=0, Actual=1, Confidence=0.484\n",
      "Sample 5: Predicted=2, Actual=2, Confidence=0.781\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "model = results['model']\n",
    "predictions = predict(model=model, data=X_test[:5])\n",
    "probabilities = model.predict_proba(X_test[:5])\n",
    "\n",
    "print(\"🔮 Predictions for first 5 test samples:\")\n",
    "for i in range(5):\n",
    "    print(f\"Sample {i+1}: Predicted={predictions[i]}, Actual={y_test[i]}, Confidence={probabilities[i].max():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936fb848",
   "metadata": {},
   "source": [
    "## 🧠 Example 2: PyTorch Neural Network\n",
    "\n",
    "Now let's create a PyTorch neural network for the same task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb6aa5a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 PyTorch Neural Network Configuration:\n",
      "Layers: 6\n",
      "Training epochs: 50\n"
     ]
    }
   ],
   "source": [
    "# Create PyTorch configuration\n",
    "pytorch_config = DLTConfig(\n",
    "    model_type='torch.nn.Sequential',\n",
    "    model_params={\n",
    "        'layers': [\n",
    "            {'type': 'Linear', 'in_features': 20, 'out_features': 64},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.2},\n",
    "            {'type': 'Linear', 'in_features': 64, 'out_features': 32},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Linear', 'in_features': 32, 'out_features': 3}\n",
    "        ]\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 50,\n",
    "        'batch_size': 32,\n",
    "        'optimizer': {'type': 'adam', 'lr': 0.001},\n",
    "        'loss': {'type': 'cross_entropy'},\n",
    "        'early_stopping': {'patience': 10}\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'pytorch_quickstart',\n",
    "        'tags': ['neural_network', 'pytorch']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"🧠 PyTorch Neural Network Configuration:\")\n",
    "print(f\"Layers: {len(pytorch_config.model_params['layers'])}\")\n",
    "print(f\"Training epochs: {pytorch_config.training['epochs']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34c478af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with torch.nn.Sequential\n",
      "Framework: torch\n",
      "Device: cuda:0\n",
      "Training torch.nn.Sequential...\n",
      "Using configured task type: classification\n",
      "Epoch 1/50, Loss: 0.9905\n",
      "Epoch 1/50, Loss: 0.9905\n",
      "Epoch 11/50, Loss: 0.3997\n",
      "Epoch 11/50, Loss: 0.3997\n",
      "Epoch 21/50, Loss: 0.2605\n",
      "Epoch 21/50, Loss: 0.2605\n",
      "Epoch 31/50, Loss: 0.2032\n",
      "Epoch 31/50, Loss: 0.2032\n",
      "Epoch 41/50, Loss: 0.1929\n",
      "Epoch 41/50, Loss: 0.1929\n",
      "Training completed in 1.99s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.8900\n",
      "Training completed in 1.99 seconds\n",
      "\n",
      "🚀 PyTorch Training Results:\n",
      "Training completed in 1.99 seconds\n",
      "Final training loss: N/A\n",
      "Test accuracy: 0.89\n",
      "Training completed in 1.99s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.8900\n",
      "Training completed in 1.99 seconds\n",
      "\n",
      "🚀 PyTorch Training Results:\n",
      "Training completed in 1.99 seconds\n",
      "Final training loss: N/A\n",
      "Test accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Train PyTorch model\n",
    "pytorch_results = train(\n",
    "    config=pytorch_config,\n",
    "    train_data=(X_train.astype(np.float32), y_train),\n",
    "    test_data=(X_test.astype(np.float32), y_test),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n🚀 PyTorch Training Results:\")\n",
    "print(f\"Training completed in {pytorch_results['training_time']:.2f} seconds\")\n",
    "print(f\"Final training loss: {pytorch_results['training_results'].get('history', {}).get('train_loss', ['N/A'])[-1]}\")\n",
    "print(f\"Test accuracy: {pytorch_results.get('test_results', {}).get('accuracy', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b896dd",
   "metadata": {},
   "source": [
    "## ⚙️ Example 3: Hyperparameter Optimization\n",
    "\n",
    "DLT includes powerful hyperparameter optimization using Optuna:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1e70bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:28,139] A new study created in memory with name: no-name-f32120de-2ccc-42a2-ba10-8a01a59fc35c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Starting hyperparameter optimization...\n",
      "Search space: 4 parameters\n",
      "Starting hyperparameter optimization with 20 trials...\n",
      "Optimizing val_loss (minimize)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:   5%|▌         | 1/20 [00:00<00:03,  5.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:28,317] Trial 0 finished with value: inf and parameters: {'model_params.n_estimators': 81, 'model_params.max_depth': 16, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 4}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  10%|█         | 2/20 [00:00<00:03,  5.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:28,512] Trial 1 finished with value: inf and parameters: {'model_params.n_estimators': 92, 'model_params.max_depth': 15, 'model_params.min_samples_split': 18, 'model_params.min_samples_leaf': 2}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  15%|█▌        | 3/20 [00:00<00:02,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:28,671] Trial 2 finished with value: inf and parameters: {'model_params.n_estimators': 116, 'model_params.max_depth': 3, 'model_params.min_samples_split': 8, 'model_params.min_samples_leaf': 8}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  25%|██▌       | 5/20 [00:00<00:02,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:28,896] Trial 3 finished with value: inf and parameters: {'model_params.n_estimators': 105, 'model_params.max_depth': 10, 'model_params.min_samples_split': 6, 'model_params.min_samples_leaf': 3}. Best is trial 0 with value: inf.\n",
      "[I 2025-09-29 12:06:29,033] Trial 4 finished with value: inf and parameters: {'model_params.n_estimators': 76, 'model_params.max_depth': 7, 'model_params.min_samples_split': 9, 'model_params.min_samples_leaf': 10}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  30%|███       | 6/20 [00:01<00:02,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:29,170] Trial 5 finished with value: inf and parameters: {'model_params.n_estimators': 88, 'model_params.max_depth': 4, 'model_params.min_samples_split': 8, 'model_params.min_samples_leaf': 4}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  35%|███▌      | 7/20 [00:01<00:02,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:29,412] Trial 6 finished with value: inf and parameters: {'model_params.n_estimators': 131, 'model_params.max_depth': 20, 'model_params.min_samples_split': 15, 'model_params.min_samples_leaf': 9}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  40%|████      | 8/20 [00:01<00:02,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:29,760] Trial 7 finished with value: inf and parameters: {'model_params.n_estimators': 195, 'model_params.max_depth': 6, 'model_params.min_samples_split': 13, 'model_params.min_samples_leaf': 5}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  45%|████▌     | 9/20 [00:01<00:02,  3.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:30,075] Trial 8 finished with value: inf and parameters: {'model_params.n_estimators': 164, 'model_params.max_depth': 13, 'model_params.min_samples_split': 2, 'model_params.min_samples_leaf': 7}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  55%|█████▌    | 11/20 [00:02<00:01,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:30,329] Trial 9 finished with value: inf and parameters: {'model_params.n_estimators': 133, 'model_params.max_depth': 8, 'model_params.min_samples_split': 2, 'model_params.min_samples_leaf': 6}. Best is trial 0 with value: inf.\n",
      "[I 2025-09-29 12:06:30,452] Trial 10 finished with value: inf and parameters: {'model_params.n_estimators': 55, 'model_params.max_depth': 18, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 1}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  65%|██████▌   | 13/20 [00:02<00:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:30,565] Trial 11 finished with value: inf and parameters: {'model_params.n_estimators': 52, 'model_params.max_depth': 15, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 2}. Best is trial 0 with value: inf.\n",
      "[I 2025-09-29 12:06:30,750] Trial 12 finished with value: inf and parameters: {'model_params.n_estimators': 88, 'model_params.max_depth': 16, 'model_params.min_samples_split': 17, 'model_params.min_samples_leaf': 3}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  70%|███████   | 14/20 [00:02<00:01,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:30,911] Trial 13 finished with value: inf and parameters: {'model_params.n_estimators': 73, 'model_params.max_depth': 13, 'model_params.min_samples_split': 17, 'model_params.min_samples_leaf': 1}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  75%|███████▌  | 15/20 [00:02<00:00,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:31,121] Trial 14 finished with value: inf and parameters: {'model_params.n_estimators': 103, 'model_params.max_depth': 16, 'model_params.min_samples_split': 17, 'model_params.min_samples_leaf': 4}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  85%|████████▌ | 17/20 [00:03<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:31,444] Trial 15 finished with value: inf and parameters: {'model_params.n_estimators': 160, 'model_params.max_depth': 20, 'model_params.min_samples_split': 13, 'model_params.min_samples_leaf': 5}. Best is trial 0 with value: inf.\n",
      "[I 2025-09-29 12:06:31,588] Trial 16 finished with value: inf and parameters: {'model_params.n_estimators': 69, 'model_params.max_depth': 11, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 3}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf:  90%|█████████ | 18/20 [00:03<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:31,803] Trial 17 finished with value: inf and parameters: {'model_params.n_estimators': 101, 'model_params.max_depth': 14, 'model_params.min_samples_split': 18, 'model_params.min_samples_leaf': 2}. Best is trial 0 with value: inf.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: inf: 100%|██████████| 20/20 [00:04<00:00,  4.83it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-29 12:06:32,096] Trial 18 finished with value: inf and parameters: {'model_params.n_estimators': 149, 'model_params.max_depth': 18, 'model_params.min_samples_split': 14, 'model_params.min_samples_leaf': 6}. Best is trial 0 with value: inf.\n",
      "[I 2025-09-29 12:06:32,283] Trial 19 finished with value: inf and parameters: {'model_params.n_estimators': 88, 'model_params.max_depth': 17, 'model_params.min_samples_split': 11, 'model_params.min_samples_leaf': 4}. Best is trial 0 with value: inf.\n",
      "Best trial value: inf\n",
      "Best parameters:\n",
      "  model_params.n_estimators: 81\n",
      "  model_params.max_depth: 16\n",
      "  model_params.min_samples_split: 20\n",
      "  model_params.min_samples_leaf: 4\n",
      "Starting training with sklearn.ensemble.RandomForestClassifier\n",
      "Framework: sklearn\n",
      "Device: cuda:0\n",
      "Training sklearn.ensemble.RandomForestClassifier...\n",
      "Training completed in 0.16s\n",
      "Training completed in 0.16 seconds\n",
      "\n",
      "🏆 Optimization Results:\n",
      "Best score: inf\n",
      "Best parameters: {'model_params.n_estimators': 81, 'model_params.max_depth': 16, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 4}\n",
      "Training completed in 0.16s\n",
      "Training completed in 0.16 seconds\n",
      "\n",
      "🏆 Optimization Results:\n",
      "Best score: inf\n",
      "Best parameters: {'model_params.n_estimators': 81, 'model_params.max_depth': 16, 'model_params.min_samples_split': 20, 'model_params.min_samples_leaf': 4}\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameter search space\n",
    "base_config = {\n",
    "    'model_type': 'sklearn.ensemble.RandomForestClassifier',\n",
    "    'model_params': {'random_state': 42}\n",
    "}\n",
    "\n",
    "param_space = {\n",
    "    'model_params.n_estimators': (50, 200),\n",
    "    'model_params.max_depth': (3, 20),\n",
    "    'model_params.min_samples_split': (2, 20),\n",
    "    'model_params.min_samples_leaf': (1, 10)\n",
    "}\n",
    "\n",
    "print(\"🔍 Starting hyperparameter optimization...\")\n",
    "print(f\"Search space: {len(param_space)} parameters\")\n",
    "\n",
    "# Run optimization\n",
    "optimization_results = tune(\n",
    "    base_config=base_config,\n",
    "    config_space=param_space,\n",
    "    train_data=(X_train, y_train),\n",
    "    val_data=(X_test, y_test),\n",
    "    n_trials=20,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n🏆 Optimization Results:\")\n",
    "print(f\"Best score: {optimization_results['best_value']}\")\n",
    "print(f\"Best parameters: {optimization_results['best_params']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f852f94a",
   "metadata": {},
   "source": [
    "## 💾 Example 4: Model Persistence\n",
    "\n",
    "Save and load models easily:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8895c4da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 Model saved to: tmpvjw8lif3.pkl\n",
      "📋 Config saved to: tmp_qlp4de1.yaml\n",
      "\n",
      "✅ Model loaded successfully!\n",
      "Predictions match: True\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Save the best model\n",
    "best_model = optimization_results['best_model']\n",
    "best_config = optimization_results['best_config']\n",
    "\n",
    "# Create temporary files for demo using mkstemp (secure)\n",
    "model_fd, model_path = tempfile.mkstemp(suffix='.pkl')\n",
    "config_fd, config_path = tempfile.mkstemp(suffix='.yaml')\n",
    "\n",
    "try:\n",
    "    # Close the file descriptors since we only need the paths\n",
    "    os.close(model_fd)\n",
    "    os.close(config_fd)\n",
    "    \n",
    "    # Save model and config\n",
    "    best_model.save(model_path)\n",
    "    best_config.save(config_path)\n",
    "    \n",
    "    print(f\"💾 Model saved to: {os.path.basename(model_path)}\")\n",
    "    print(f\"📋 Config saved to: {os.path.basename(config_path)}\")\n",
    "    \n",
    "    # Load model and config\n",
    "    loaded_config = DLTConfig.from_file(config_path)\n",
    "    loaded_model = DLTModel.load(model_path, loaded_config)\n",
    "    \n",
    "    # Test loaded model\n",
    "    test_predictions = loaded_model.predict(X_test[:3])\n",
    "    original_predictions = best_model.predict(X_test[:3])\n",
    "    \n",
    "    print(f\"\\n✅ Model loaded successfully!\")\n",
    "    print(f\"Predictions match: {np.array_equal(test_predictions, original_predictions)}\")\n",
    "    \n",
    "finally:\n",
    "    # Clean up temporary files\n",
    "    for path in [model_path, config_path]:\n",
    "        if os.path.exists(path):\n",
    "            os.unlink(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae00e467",
   "metadata": {},
   "source": [
    "## 📊 Example 5: Configuration Management\n",
    "\n",
    "DLT provides flexible configuration management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35f75c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛠️ Advanced Configuration:\n",
      "Framework: sklearn\n",
      "Model: sklearn.svm.SVC\n",
      "Experiment: advanced_svm_experiment\n",
      "Tags: svm, classification, rbf_kernel\n",
      "\n",
      "📋 Configuration keys: ['model_type', 'model_params', 'training', 'data', 'experiment', 'hardware', 'performance', 'optimization']\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive configuration\n",
    "advanced_config = DLTConfig(\n",
    "    model_type='sklearn.svm.SVC',\n",
    "    model_params={\n",
    "        'kernel': 'rbf',\n",
    "        'C': 1.0,\n",
    "        'probability': True,\n",
    "        'random_state': 42\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'advanced_svm_experiment',\n",
    "        'tags': ['svm', 'classification', 'rbf_kernel'],\n",
    "        'notes': 'Testing SVM with RBF kernel',\n",
    "        'seed': 42\n",
    "    },\n",
    "    hardware={\n",
    "        'device': 'cpu',\n",
    "        'num_workers': 4\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"🛠️ Advanced Configuration:\")\n",
    "print(f\"Framework: {advanced_config.get_framework()}\")\n",
    "print(f\"Model: {advanced_config.model_type}\")\n",
    "print(f\"Experiment: {advanced_config.experiment['name']}\")\n",
    "print(f\"Tags: {', '.join(advanced_config.experiment['tags'])}\")\n",
    "\n",
    "# Convert to dictionary for inspection\n",
    "config_dict = advanced_config.to_dict()\n",
    "print(f\"\\n📋 Configuration keys: {list(config_dict.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69284ddc",
   "metadata": {},
   "source": [
    "## 🎯 Summary\n",
    "\n",
    "In this quick start guide, you've learned how to:\n",
    "\n",
    "✅ **Create configurations** for different ML frameworks  \n",
    "✅ **Train models** with sklearn and PyTorch  \n",
    "✅ **Optimize hyperparameters** automatically  \n",
    "✅ **Save and load** models and configurations  \n",
    "✅ **Manage complex configurations** with validation  \n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore `02_advanced_features.ipynb` for GPU training, mixed precision, and distributed training\n",
    "- Check `03_multi_framework_comparison.ipynb` to compare different ML frameworks\n",
    "- See `04_production_deployment.ipynb` for production best practices\n",
    "\n",
    "### 📚 Resources:\n",
    "\n",
    "- **Documentation**: Check the `tests/` folder for comprehensive examples\n",
    "- **Configuration**: See `src/dlt/core/config.py` for all configuration options\n",
    "- **Examples**: Explore other notebooks in this folder\n",
    "\n",
    "Happy training! 🚀"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
