{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82c5d44",
   "metadata": {},
   "source": [
    "# DLT Advanced Features Guide\n",
    "\n",
    "This notebook demonstrates the advanced capabilities of the DLT framework including:\n",
    "- ðŸš€ GPU acceleration and mixed precision training\n",
    "- ðŸ“Š Performance profiling and monitoring\n",
    "- ðŸŽ¯ Advanced loss functions and smart weighting\n",
    "- âš¡ Distributed training setup\n",
    "- ðŸ”§ Custom model architectures\n",
    "\n",
    "Let's explore these powerful features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966a5dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-29 09:59:26.449477: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/rlfowler/Documents/myprojects/DLT/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "GPU device: NVIDIA RTX A5000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# DLT imports\n",
    "from dlt.core.config import DLTConfig\n",
    "from dlt.core.model import DLTModel\n",
    "from dlt.core.pipeline import train, evaluate\n",
    "from dlt.utils.performance import GPUManager, PerformanceProfiler\n",
    "from dlt.utils.loss import SmartLossFunction, CombinedLoss, ClassificationLoss\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73340176",
   "metadata": {},
   "source": [
    "## ðŸš€ GPU Acceleration & Mixed Precision Training\n",
    "\n",
    "DLT automatically detects and utilizes GPU resources with smart optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c3d8bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 8000 training samples, 100 features\n",
      "Classes: 5\n"
     ]
    }
   ],
   "source": [
    "# Create larger dataset for GPU training demonstration\n",
    "X, y = make_classification(\n",
    "    n_samples=10000,\n",
    "    n_features=100,\n",
    "    n_classes=5,\n",
    "    n_informative=80,\n",
    "    n_redundant=0,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Dataset: {X_train.shape[0]} training samples, {X_train.shape[1]} features\")\n",
    "print(f\"Classes: {len(np.unique(y))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "430f9ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ GPU Configuration:\n",
      "Device: auto\n",
      "Mixed precision: auto\n",
      "Model compilation: auto\n",
      "Profiling enabled: True\n"
     ]
    }
   ],
   "source": [
    "# Configure GPU training with mixed precision\n",
    "gpu_config = DLTConfig(\n",
    "    model_type='torch.nn.Sequential',\n",
    "    model_params={\n",
    "        'layers': [\n",
    "            {'type': 'Linear', 'in_features': 100, 'out_features': 256},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 256},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.3},\n",
    "            {'type': 'Linear', 'in_features': 256, 'out_features': 128},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 128},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.2},\n",
    "            {'type': 'Linear', 'in_features': 128, 'out_features': 5}\n",
    "        ]\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 20,\n",
    "        'batch_size': 256,\n",
    "        'optimizer': {'type': 'adamw', 'lr': 0.001, 'weight_decay': 0.01},\n",
    "        'scheduler': {'type': 'cosine', 'T_max': 20},\n",
    "        'early_stopping': {'patience': 5}\n",
    "    },\n",
    "    hardware={\n",
    "        'device': 'auto',  # Automatically select GPU if available\n",
    "        'num_workers': 4,\n",
    "        'pin_memory': True\n",
    "    },\n",
    "    performance={\n",
    "        'mixed_precision': {'enabled': 'auto'},  # Enable mixed precision if supported\n",
    "        'compile': {'enabled': 'auto'},  # PyTorch 2.0 compilation\n",
    "        'memory_optimization': True,\n",
    "        'profiling': {'enabled': True, 'memory': True, 'compute': True}\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'gpu_mixed_precision_demo'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âš¡ GPU Configuration:\")\n",
    "print(f\"Device: {gpu_config.hardware['device']}\")\n",
    "print(f\"Mixed precision: {gpu_config.performance['mixed_precision']['enabled']}\")\n",
    "print(f\"Model compilation: {gpu_config.performance['compile']['enabled']}\")\n",
    "print(f\"Profiling enabled: {gpu_config.performance['profiling']['enabled']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44f36791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Starting GPU training...\n",
      "Starting training with torch.nn.Sequential\n",
      "Framework: torch\n",
      "Device: cuda:0\n",
      "Training torch.nn.Sequential...\n",
      "Epoch 1/20, Loss: 1.1008\n",
      "Epoch 5/20, Loss: 0.4381\n",
      "Epoch 9/20, Loss: 0.2250\n",
      "Epoch 13/20, Loss: 0.1464\n",
      "Epoch 17/20, Loss: 0.1045\n",
      "Training completed in 1.42s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.9570\n",
      "Training completed in 1.42 seconds\n",
      "\n",
      "ðŸ Training completed in 1.42 seconds\n",
      "Test accuracy: 0.957\n"
     ]
    }
   ],
   "source": [
    "# Train with GPU acceleration\n",
    "print(\"ðŸš€ Starting GPU training...\")\n",
    "\n",
    "gpu_results = train(\n",
    "    config=gpu_config,\n",
    "    train_data=(X_train.astype(np.float32), y_train),\n",
    "    test_data=(X_test.astype(np.float32), y_test),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ Training completed in {gpu_results['training_time']:.2f} seconds\")\n",
    "print(f\"Test accuracy: {gpu_results.get('test_results', {}).get('accuracy', 'N/A')}\")\n",
    "\n",
    "# Show training history\n",
    "history = gpu_results['training_results'].get('history', {})\n",
    "if 'train_loss' in history:\n",
    "    print(f\"Final train loss: {history['train_loss'][-1]:.4f}\")\n",
    "if 'val_loss' in history:\n",
    "    print(f\"Final validation loss: {history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd8414",
   "metadata": {},
   "source": [
    "## ðŸ“Š Performance Profiling & Monitoring\n",
    "\n",
    "Analyze training performance and identify bottlenecks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65e2951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” GPU Information:\n",
      "CUDA available: True\n",
      "GPU count: 4\n",
      "Current device: 0\n",
      "Device name: NVIDIA RTX A5000\n",
      "Memory allocated: 0.0 MB\n",
      "\n",
      "ðŸ“ˆ Performance Profiling:\n",
      "Profiling results: {'step_timings': {'data_preparation': {'avg_ms': np.float64(193.0524290073663), 'min_ms': np.float64(193.0524290073663), 'max_ms': np.float64(193.0524290073663), 'std_ms': np.float64(0.0), 'count': 1}, 'model_forward': {'avg_ms': np.float64(84.02242185547948), 'min_ms': np.float64(84.02242185547948), 'max_ms': np.float64(84.02242185547948), 'std_ms': np.float64(0.0), 'count': 1}}, 'memory_usage': {'peak_memory_mb': np.float64(8.52880859375), 'avg_memory_mb': np.float64(4.264404296875), 'avg_memory_delta_mb': np.float64(4.264404296875), 'max_memory_delta_mb': np.float64(8.52880859375)}}\n",
      "\n",
      "âš ï¸ Potential bottlenecks:\n",
      "  - Operation 'data_preparation' is taking 69.7% of time\n",
      "  - Operation 'model_forward' is taking 30.3% of time\n",
      "\n",
      "ðŸ”‹ GPU Memory Usage:\n",
      "Memory allocated: 8.5 MB\n",
      "Memory cached: 22.0 MB\n",
      "Profiling results: {'step_timings': {'data_preparation': {'avg_ms': np.float64(193.0524290073663), 'min_ms': np.float64(193.0524290073663), 'max_ms': np.float64(193.0524290073663), 'std_ms': np.float64(0.0), 'count': 1}, 'model_forward': {'avg_ms': np.float64(84.02242185547948), 'min_ms': np.float64(84.02242185547948), 'max_ms': np.float64(84.02242185547948), 'std_ms': np.float64(0.0), 'count': 1}}, 'memory_usage': {'peak_memory_mb': np.float64(8.52880859375), 'avg_memory_mb': np.float64(4.264404296875), 'avg_memory_delta_mb': np.float64(4.264404296875), 'max_memory_delta_mb': np.float64(8.52880859375)}}\n",
      "\n",
      "âš ï¸ Potential bottlenecks:\n",
      "  - Operation 'data_preparation' is taking 69.7% of time\n",
      "  - Operation 'model_forward' is taking 30.3% of time\n",
      "\n",
      "ðŸ”‹ GPU Memory Usage:\n",
      "Memory allocated: 8.5 MB\n",
      "Memory cached: 22.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize performance profiler (skip GPUManager due to distributed training conflicts in notebooks)\n",
    "profiler = PerformanceProfiler(gpu_config.performance)\n",
    "\n",
    "print(\"ðŸ” GPU Information:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU count: {torch.cuda.device_count()}\")\n",
    "    print(f\"Current device: {torch.cuda.current_device()}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n",
    "\n",
    "print(\"\\nðŸ“ˆ Performance Profiling:\")\n",
    "with profiler.profile_step(\"data_preparation\"):\n",
    "    # Simulate data preparation work\n",
    "    dummy_data = torch.randn(1000, 100)\n",
    "    processed_data = dummy_data * 2 + 1\n",
    "\n",
    "with profiler.profile_step(\"model_forward\"):\n",
    "    # Simulate model forward pass\n",
    "    if torch.cuda.is_available():\n",
    "        model_demo = torch.nn.Linear(100, 5).cuda()\n",
    "        output = model_demo(dummy_data.cuda())\n",
    "    else:\n",
    "        model_demo = torch.nn.Linear(100, 5)\n",
    "        output = model_demo(dummy_data)\n",
    "\n",
    "# Get performance summary\n",
    "performance_summary = profiler.get_performance_summary()\n",
    "print(f\"Profiling results: {performance_summary}\")\n",
    "\n",
    "# Identify bottlenecks\n",
    "bottlenecks = profiler.identify_bottlenecks()\n",
    "if bottlenecks:\n",
    "    print(f\"\\nâš ï¸ Potential bottlenecks:\")\n",
    "    for bottleneck in bottlenecks:\n",
    "        print(f\"  - {bottleneck}\")\n",
    "else:\n",
    "    print(\"\\nâœ… No significant bottlenecks detected\")\n",
    "\n",
    "# Additional GPU memory info\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"\\nðŸ”‹ GPU Memory Usage:\")\n",
    "    print(f\"Memory allocated: {torch.cuda.memory_allocated() / 1024**2:.1f} MB\")\n",
    "    print(f\"Memory cached: {torch.cuda.memory_reserved() / 1024**2:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad8365f",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Advanced Loss Functions\n",
    "\n",
    "DLT provides sophisticated loss functions with smart weighting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d10d4f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {np.int64(0): np.int64(3478), np.int64(1): np.int64(1011), np.int64(2): np.int64(511)}\n",
      "Class imbalance ratio: 6.81\n"
     ]
    }
   ],
   "source": [
    "# Create imbalanced dataset for loss function demo\n",
    "X_imbalanced, y_imbalanced = make_classification(\n",
    "    n_samples=5000,\n",
    "    n_features=50,\n",
    "    n_classes=3,\n",
    "    n_informative=40,\n",
    "    n_redundant=0,\n",
    "    weights=[0.7, 0.2, 0.1],  # Imbalanced classes\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Check class distribution\n",
    "unique, counts = np.unique(y_imbalanced, return_counts=True)\n",
    "class_distribution = dict(zip(unique, counts))\n",
    "print(f\"Class distribution: {class_distribution}\")\n",
    "print(f\"Class imbalance ratio: {max(counts)/min(counts):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abc41874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ Advanced Loss Configuration:\n",
      "Loss type: focal\n",
      "Focal gamma: 2.0\n",
      "Class weights: [0.25, 0.5, 0.8]\n",
      "Adaptive weighting: True\n",
      "Label smoothing: 0.1\n"
     ]
    }
   ],
   "source": [
    "# Configure advanced loss functions\n",
    "advanced_loss_config = DLTConfig(\n",
    "    model_type='torch.nn.Sequential',\n",
    "    model_params={\n",
    "        'layers': [\n",
    "            {'type': 'Linear', 'in_features': 50, 'out_features': 128},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.3},\n",
    "            {'type': 'Linear', 'in_features': 128, 'out_features': 64},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Linear', 'in_features': 64, 'out_features': 3}\n",
    "        ]\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 15,\n",
    "        'batch_size': 128,\n",
    "        'optimizer': {'type': 'adam', 'lr': 0.001},\n",
    "        'loss': {\n",
    "            'type': 'focal',  # Focal loss for imbalanced data\n",
    "            'alpha': [0.25, 0.5, 0.8],  # Class-specific weights\n",
    "            'gamma': 2.0,  # Focal loss gamma parameter\n",
    "            'adaptive_weighting': True,  # Dynamic loss reweighting\n",
    "            'label_smoothing': 0.1  # Label smoothing\n",
    "        }\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'advanced_loss_demo'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ðŸŽ¯ Advanced Loss Configuration:\")\n",
    "print(f\"Loss type: {advanced_loss_config.training['loss']['type']}\")\n",
    "print(f\"Focal gamma: {advanced_loss_config.training['loss']['gamma']}\")\n",
    "print(f\"Class weights: {advanced_loss_config.training['loss']['alpha']}\")\n",
    "print(f\"Adaptive weighting: {advanced_loss_config.training['loss']['adaptive_weighting']}\")\n",
    "print(f\"Label smoothing: {advanced_loss_config.training['loss']['label_smoothing']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1bc41e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”„ Combined Loss Functions:\n",
      "Number of components: 2\n",
      "Component names: ['loss_1', 'loss_2']\n",
      "Sample combined loss value: 0.5045\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate combined loss functions\n",
    "combined_loss_config = {\n",
    "    'components': [\n",
    "        {\n",
    "            'category': 'classification',\n",
    "            'type': 'cross_entropy',  # Use cross_entropy type with focal=True\n",
    "            'weight': 0.7,\n",
    "            'focal': True,\n",
    "            'focal_gamma': 2.0,\n",
    "            'focal_alpha': 0.25\n",
    "        },\n",
    "        {\n",
    "            'category': 'classification', \n",
    "            'type': 'cross_entropy',\n",
    "            'weight': 0.3,\n",
    "            'label_smoothing': 0.1\n",
    "        }\n",
    "    ],\n",
    "    'adaptive_weighting': True\n",
    "}\n",
    "\n",
    "combined_loss = CombinedLoss(combined_loss_config)\n",
    "print(f\"\\nðŸ”„ Combined Loss Functions:\")\n",
    "print(f\"Number of components: {len(combined_loss.loss_functions)}\")\n",
    "print(f\"Component names: {combined_loss.loss_names}\")\n",
    "\n",
    "# Test combined loss\n",
    "dummy_predictions = torch.randn(32, 3)\n",
    "dummy_targets = torch.randint(0, 3, (32,))\n",
    "\n",
    "loss_value = combined_loss(dummy_predictions, dummy_targets)\n",
    "print(f\"Sample combined loss value: {loss_value.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c42702",
   "metadata": {},
   "source": [
    "## âš¡ Distributed Training Configuration\n",
    "\n",
    "Configure multi-GPU distributed training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485753dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš¡ Distributed Training Configuration:\n",
      "Distributed backend: nccl\n",
      "Distributed enabled: False\n",
      "Mixed precision: True\n",
      "Compilation mode: max-autotune\n",
      "Batch size: 512\n",
      "\n",
      "ðŸ–¥ï¸ Hardware Setup:\n",
      "CUDA available: True\n",
      "Available GPUs: 4\n",
      "  GPU 0: NVIDIA RTX A5000\n",
      "  GPU 1: NVIDIA RTX A5000\n",
      "  GPU 2: NVIDIA RTX A5000\n",
      "  GPU 3: NVIDIA RTX A5000\n",
      "Distributed training: Disabled (for notebook compatibility)\n",
      "\n",
      "ðŸ“ Note: In production environments with multiple GPUs, set:\n",
      "  distributed.enabled = 'auto' or True\n",
      "  Use proper process launching (torchrun, mpirun, etc.)\n",
      "  Current config is safe for notebook demonstration\n"
     ]
    }
   ],
   "source": [
    "# Configure distributed training\n",
    "distributed_config = DLTConfig(\n",
    "    model_type='torch.nn.Sequential',\n",
    "    model_params={\n",
    "        'layers': [\n",
    "            {'type': 'Linear', 'in_features': 100, 'out_features': 512},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 512},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.2},\n",
    "            {'type': 'Linear', 'in_features': 512, 'out_features': 256},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 256},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Linear', 'in_features': 256, 'out_features': 5}\n",
    "        ]\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 10,\n",
    "        'batch_size': 512,  # Larger batch size for distributed training\n",
    "        'optimizer': {'type': 'sgd', 'lr': 0.01, 'momentum': 0.9, 'weight_decay': 1e-4}\n",
    "    },\n",
    "    hardware={\n",
    "        'device': 'auto',\n",
    "        'gpu_ids': None,  # Use all available GPUs\n",
    "        'distributed': {\n",
    "            'enabled': False,  # Disable distributed for notebook demo to prevent hanging\n",
    "            'backend': 'nccl',  # NCCL for GPU communication\n",
    "            'find_unused_parameters': False,\n",
    "            'static_graph': True  # Optimize for static computation graph\n",
    "        }\n",
    "    },\n",
    "    performance={\n",
    "        'mixed_precision': {'enabled': True},\n",
    "        'compile': {'enabled': True, 'mode': 'max-autotune'},\n",
    "        'memory_optimization': True\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'distributed_training_demo'\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"âš¡ Distributed Training Configuration:\")\n",
    "print(f\"Distributed backend: {distributed_config.hardware['distributed']['backend']}\")\n",
    "print(f\"Distributed enabled: {distributed_config.hardware['distributed']['enabled']}\")\n",
    "print(f\"Mixed precision: {distributed_config.performance['mixed_precision']['enabled']}\")\n",
    "print(f\"Compilation mode: {distributed_config.performance['compile']['mode']}\")\n",
    "print(f\"Batch size: {distributed_config.training['batch_size']}\")\n",
    "\n",
    "# Show hardware information without initializing distributed GPUManager\n",
    "print(f\"\\nðŸ–¥ï¸ Hardware Setup:\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Available GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "print(f\"Distributed training: {'Enabled' if distributed_config.hardware['distributed']['enabled'] else 'Disabled (for notebook compatibility)'}\")\n",
    "\n",
    "# Note about distributed training in production\n",
    "print(f\"\\nðŸ“ Note: In production environments with multiple GPUs, set:\")\n",
    "print(f\"  distributed.enabled = 'auto' or True\")\n",
    "print(f\"  Use proper process launching (torchrun, mpirun, etc.)\")\n",
    "print(f\"  Current config is safe for notebook demonstration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de69f11",
   "metadata": {},
   "source": [
    "## ðŸ”§ Custom Model Architectures\n",
    "\n",
    "Create sophisticated neural network architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d410198d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Custom Architecture Configuration:\n",
      "Total layers: 18\n",
      "Optimizer: adamw\n",
      "Learning rate scheduler: cosine\n",
      "Gradient clipping: True\n",
      "Label smoothing: 0.1\n",
      "\n",
      "ðŸ“‹ Model Information:\n",
      "Framework: torch\n",
      "Model type: torch.nn.Sequential\n",
      "Device: cuda\n",
      "Total parameters: 209,541\n",
      "Trainable parameters: 209,541\n"
     ]
    }
   ],
   "source": [
    "# Define a custom ResNet-style block configuration\n",
    "resnet_style_config = DLTConfig(\n",
    "    model_type='torch.nn.Sequential',\n",
    "    model_params={\n",
    "        'layers': [\n",
    "            # Input layer\n",
    "            {'type': 'Linear', 'in_features': 100, 'out_features': 256},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 256},\n",
    "            {'type': 'ReLU'},\n",
    "            \n",
    "            # First residual-style block\n",
    "            {'type': 'Linear', 'in_features': 256, 'out_features': 256},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 256},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.1},\n",
    "            \n",
    "            {'type': 'Linear', 'in_features': 256, 'out_features': 256},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 256},\n",
    "            {'type': 'ReLU'},\n",
    "            \n",
    "            # Second block with dimension reduction\n",
    "            {'type': 'Linear', 'in_features': 256, 'out_features': 128},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 128},\n",
    "            {'type': 'ReLU'},\n",
    "            {'type': 'Dropout', 'p': 0.2},\n",
    "            \n",
    "            {'type': 'Linear', 'in_features': 128, 'out_features': 128},\n",
    "            {'type': 'BatchNorm1d', 'num_features': 128},\n",
    "            {'type': 'ReLU'},\n",
    "            \n",
    "            # Output layer\n",
    "            {'type': 'Linear', 'in_features': 128, 'out_features': 5}\n",
    "        ]\n",
    "    },\n",
    "    training={\n",
    "        'epochs': 25,\n",
    "        'batch_size': 128,\n",
    "        'optimizer': {\n",
    "            'type': 'adamw',\n",
    "            'lr': 0.001,\n",
    "            'weight_decay': 0.01,\n",
    "            'betas': [0.9, 0.999],\n",
    "            'eps': 1e-8\n",
    "        },\n",
    "        'scheduler': {\n",
    "            'type': 'cosine',\n",
    "            'T_max': 25,\n",
    "            'eta_min': 1e-6\n",
    "        },\n",
    "        'loss': {\n",
    "            'type': 'cross_entropy',\n",
    "            'label_smoothing': 0.1\n",
    "        },\n",
    "        'early_stopping': {\n",
    "            'patience': 8,\n",
    "            'min_delta': 1e-4\n",
    "        },\n",
    "        'gradient_clipping': {\n",
    "            'enabled': True,\n",
    "            'max_norm': 1.0\n",
    "        }\n",
    "    },\n",
    "    experiment={\n",
    "        'name': 'custom_architecture_demo',\n",
    "        'tags': ['custom', 'resnet_style', 'deep']\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"ðŸ”§ Custom Architecture Configuration:\")\n",
    "print(f\"Total layers: {len(resnet_style_config.model_params['layers'])}\")\n",
    "print(f\"Optimizer: {resnet_style_config.training['optimizer']['type']}\")\n",
    "print(f\"Learning rate scheduler: {resnet_style_config.training['scheduler']['type']}\")\n",
    "print(f\"Gradient clipping: {resnet_style_config.training['gradient_clipping']['enabled']}\")\n",
    "print(f\"Label smoothing: {resnet_style_config.training['loss']['label_smoothing']}\")\n",
    "\n",
    "# Create and inspect the model\n",
    "custom_model = DLTModel.from_config(resnet_style_config)\n",
    "model_info = custom_model.get_model_info()\n",
    "\n",
    "print(f\"\\nðŸ“‹ Model Information:\")\n",
    "print(f\"Framework: {model_info['framework']}\")\n",
    "print(f\"Model type: {model_info['model_type']}\")\n",
    "print(f\"Device: {model_info.get('device', 'Unknown')}\")\n",
    "\n",
    "# Count parameters\n",
    "if hasattr(custom_model._model, 'parameters'):\n",
    "    total_params = sum(p.numel() for p in custom_model._model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in custom_model._model.parameters() if p.requires_grad)\n",
    "    print(f\"Total parameters: {total_params:,}\")\n",
    "    print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c703c0c8",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Training with Advanced Monitoring\n",
    "\n",
    "Train the custom model with comprehensive monitoring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2197d2b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Training custom architecture...\n",
      "Starting training with torch.nn.Sequential\n",
      "Framework: torch\n",
      "Device: cuda:0\n",
      "Training torch.nn.Sequential...\n",
      "Starting training with torch.nn.Sequential\n",
      "Framework: torch\n",
      "Device: cuda:0\n",
      "Training torch.nn.Sequential...\n",
      "Epoch 1/25, Loss: 0.6146\n",
      "Epoch 1/25, Loss: 0.6146\n",
      "Epoch 6/25, Loss: 0.0539\n",
      "Epoch 6/25, Loss: 0.0539\n",
      "Epoch 11/25, Loss: 0.0309\n",
      "Epoch 11/25, Loss: 0.0309\n",
      "Epoch 16/25, Loss: 0.0180\n",
      "Epoch 16/25, Loss: 0.0180\n",
      "Epoch 21/25, Loss: 0.0117\n",
      "Epoch 21/25, Loss: 0.0117\n",
      "Training completed in 5.39s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.9230\n",
      "Training completed in 5.39 seconds\n",
      "\n",
      "ðŸ Custom Architecture Results:\n",
      "Training time: 5.39 seconds\n",
      "Test accuracy: 0.923\n",
      "\n",
      "ðŸŽ¯ Test Performance:\n",
      "  accuracy: 0.9230\n",
      "Training completed in 5.39s\n",
      "Evaluating on test data...\n",
      "Test accuracy: 0.9230\n",
      "Training completed in 5.39 seconds\n",
      "\n",
      "ðŸ Custom Architecture Results:\n",
      "Training time: 5.39 seconds\n",
      "Test accuracy: 0.923\n",
      "\n",
      "ðŸŽ¯ Test Performance:\n",
      "  accuracy: 0.9230\n"
     ]
    }
   ],
   "source": [
    "# Train the custom architecture\n",
    "print(\"ðŸš€ Training custom architecture...\")\n",
    "\n",
    "custom_results = train(\n",
    "    config=resnet_style_config,\n",
    "    train_data=(X_train.astype(np.float32), y_train),\n",
    "    test_data=(X_test.astype(np.float32), y_test),\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸ Custom Architecture Results:\")\n",
    "print(f\"Training time: {custom_results['training_time']:.2f} seconds\")\n",
    "print(f\"Test accuracy: {custom_results.get('test_results', {}).get('accuracy', 'N/A')}\")\n",
    "\n",
    "# Analyze training history\n",
    "history = custom_results['training_results'].get('history', {})\n",
    "if history:\n",
    "    print(f\"\\nðŸ“Š Training History:\")\n",
    "    for metric, values in history.items():\n",
    "        if isinstance(values, list) and len(values) > 0:\n",
    "            print(f\"  {metric}: {values[-1]:.4f} (final)\")\n",
    "            if len(values) > 1:\n",
    "                improvement = values[-1] - values[0]\n",
    "                print(f\"    Improvement: {improvement:+.4f}\")\n",
    "\n",
    "# Model performance summary\n",
    "test_results = custom_results.get('test_results', {})\n",
    "if test_results:\n",
    "    print(f\"\\nðŸŽ¯ Test Performance:\")\n",
    "    for metric, value in test_results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa18f3",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Summary\n",
    "\n",
    "In this advanced features guide, you've explored:\n",
    "\n",
    "âœ… **GPU Acceleration** - Automatic GPU detection and mixed precision training  \n",
    "âœ… **Performance Profiling** - Bottleneck detection and optimization insights  \n",
    "âœ… **Advanced Loss Functions** - Focal loss, combined losses, and smart weighting  \n",
    "âœ… **Distributed Training** - Multi-GPU setup and configuration  \n",
    "âœ… **Custom Architectures** - Complex model designs with advanced optimizers  \n",
    "\n",
    "### Key Takeaways:\n",
    "\n",
    "- ðŸš€ DLT automatically handles GPU optimization and mixed precision\n",
    "- ðŸ“Š Built-in profiling helps identify and resolve performance bottlenecks\n",
    "- ðŸŽ¯ Advanced loss functions handle imbalanced data and complex objectives\n",
    "- âš¡ Distributed training scales seamlessly across multiple GPUs\n",
    "- ðŸ”§ Flexible architecture definition supports complex models\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Explore `03_multi_framework_comparison.ipynb` for framework comparisons\n",
    "- Check `04_production_deployment.ipynb` for deployment strategies\n",
    "- Review the test suite in `tests/` for comprehensive usage examples\n",
    "\n",
    "### ðŸ’¡ Pro Tips:\n",
    "\n",
    "1. **GPU Memory**: Use `memory_optimization: True` for large models\n",
    "2. **Mixed Precision**: Enable `auto` mode for automatic FP16 optimization\n",
    "3. **Profiling**: Enable profiling during development, disable in production\n",
    "4. **Loss Functions**: Use focal loss for imbalanced datasets\n",
    "5. **Distributed**: Increase batch size proportionally to GPU count\n",
    "\n",
    "Happy advanced training! ðŸš€âœ¨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
